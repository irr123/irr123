<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Querying documents with LLMs instead of reading them | Readin...</title><meta name=description content="Reading a technical doc cover-to-cover is like running a full table scan. A 64-page guide might only have five pages of signa..."><meta name=keywords content="AI-Assisted Learning,Non-Linear Reading,LLM,Document Analysis,Knowledge Extraction,Prompt Engineering,Future of Reading,Technical Documentation"><meta name=author content="Ivan Bogomolov"><meta name=robots content="index,follow"><link rel=canonical href=https://bogomolov.work/blog/posts/querying-documents-with-llms-instead-of-reading-them/><link rel=alternate type=application/rss+xml href=/blog/index.xml title="The Archive"><link rel=icon type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=192x192 href=/android-chrome-192x192.png><link rel=icon type=image/png sizes=512x512 href=/android-chrome-512x512.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><meta property="og:title" content="Querying documents with LLMs instead of reading them"><meta property="og:description" content="Reading a technical doc cover-to-cover is like running a full table scan. A 64-page guide might only have five pages of signal, but you grind through all 64 anyway.
I tried something different on Google’s Startup technical guide: AI agents. Instead of reading, I queried it. Treat the doc like a database.
"><meta property="og:type" content="website"><meta property="og:url" content="https://bogomolov.work/blog/posts/querying-documents-with-llms-instead-of-reading-them/"><meta property="og:logo" content="https://bogomolov.work/blog/img/the-archive.jpg"><meta property="og:image" content="https://bogomolov.work/blog/posts/querying-documents-with-llms-instead-of-reading-them/img.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@_irr123"><meta property="twitter:domain" content="bogomolov.work"><meta property="twitter:url" content="https://bogomolov.work/blog/posts/querying-documents-with-llms-instead-of-reading-them/"><meta name=twitter:title content="Querying documents with LLMs instead of reading them"><meta name=twitter:description content="Reading a technical doc cover-to-cover is like running a full table scan. A 64-page guide might only have five pages of signal, but you grind through all 64 anyway.
I tried something different on Google’s Startup technical guide: AI agents. Instead of reading, I queried it. Treat the doc like a database.
"><meta name=twitter:image content="https://bogomolov.work/blog/posts/querying-documents-with-llms-instead-of-reading-them/img.png"><meta name=theme-color content="#000000"><link rel=stylesheet href=/blog/css/styles.bundle.min.6dfd4bffb4fc60f9fc9061ace4309feccf93d5aefab8d8e2ad003d757bd5f34194e43fbde5acefb17dd532099a054926df6c8f38ff0bb741520a4064a1d4eb5c.css integrity="sha512-bf1L/7T8YPn8kGGs5DCf7M+T1a76uNjirQA9dXvV80GU5D+95azvsX3VMgmaBUkm32yPOP8Lt0FSCkBkodTrXA=="><link rel=preconnect href=https://www.googletagmanager.com><link rel=preconnect href=https://pagead2.googlesyndication.com><link rel=preconnect href=https://mc.yandex.ru></head><body a=auto><main class=page-content aria-label=Content><div class=w><div class=post-meta><a href=/blog/ aria-label="Back to Index" title="Back to Index">← Back</a><p><time datetime=2025-10-02T09:12:38+00:00>2025-10-02</time></p></div><h1>Querying documents with LLMs instead of reading them</h1><article><p>Reading a technical doc cover-to-cover is like running a full table scan. A
64-page guide might only have five pages of signal, but you grind through all 64
anyway.</p><p>I tried something different on Google’s
<a href="https://cloud.google.com/resources/content/building-ai-agents?hl=en" target=_blank rel="noopener noreferrer">Startup technical guide: AI agents</a>.
Instead of reading, I queried it. Treat the doc like a database.</p><p>This isn’t deep reading. It’s triage.</p><figure><a href=/blog/posts/querying-documents-with-llms-instead-of-reading-them/img.png target=_blank><picture><source srcset=/blog/posts/querying-documents-with-llms-instead-of-reading-them/img_hu_d9519a61305b3a1b.webp type=image/webp><source srcset=/blog/posts/querying-documents-with-llms-instead-of-reading-them/img_hu_ece4ec72142c895a.jpg type=image/jpeg><img src=/blog/posts/querying-documents-with-llms-instead-of-reading-them/img_hu_ece4ec72142c895a.jpg alt="LLM → concise insights" loading=lazy decoding=async></picture></a></figure><h2 id=the-workflow><a href=#the-workflow>#</a> The Workflow</h2><p><em>The point</em>: figure out in minutes if a doc is worth hours. <em>Two steps</em>: broad
“indexing” → targeted follow-ups.</p><h3 id=1-the-indexing-query><a href=#1-the-indexing-query>#</a> 1. The Indexing Query</h3><p>Ask the LLM to map the doc. Thesis, sub-arguments, audience, frameworks. Smarter
than a TOC:</p><blockquote><p>Analyze this document. Identify its primary thesis, its secondary arguments,
the intended audience, and any specific technical frameworks or code it
provides. Present this as a structured summary.</p></blockquote><p>A raw output might look like:</p><details><summary>with some rambling</summary><div class=details-content><p>Based on an analysis of the document, here is a structured summary.</p><h4 id=primary-thesis><a href=#primary-thesis>#</a> Primary Thesis</h4><p>The central argument of this guide is that for startups to succeed with AI, they
must move beyond simple prototyping to a disciplined, engineering-driven
methodology for building, deploying, and managing production-grade AI agents.
This systematic approach, centered on the Google Cloud ecosystem, enables the
creation of reliable, scalable, and responsible agentic systems, which provides
a significant competitive advantage.</p><h4 id=secondary-arguments><a href=#secondary-arguments>#</a> Secondary Arguments</h4><p>…</p><h4 id=intended-audience><a href=#intended-audience>#</a> Intended Audience</h4><p>…</p><h4 id=technical-frameworks-and-code><a href=#technical-frameworks-and-code>#</a> Technical Frameworks and Code</h4><ul><li>Primary Development Framework: The Agent Development Kit (ADK)</li><li>Operational Implementation: The Agent Starter Pack</li><li>Key Protocols:<ul><li>Agent2Agent (A2A)</li><li>Model Context Protocol (MCP)</li></ul></li><li>Recommended Runtime: Vertex AI Agent Engine</li><li>No-Code Alternative: Google Agentspace</li><li>Code Provision: The guide is conceptual and does not provide direct code
snippets</li></ul><p>ADK Samples repository for working code examples.</p></div></details><p><em>Already clear</em>: this is high-level, conceptual. No code here. That alone saves
time.</p><h3 id=2-the-targeted-query><a href=#2-the-targeted-query>#</a> 2. The Targeted Query</h3><p>Now pull a thread:</p><blockquote><p>You mentioned “must move beyond simple prototyping to a disciplined,
engineering-driven methodology for building, deploying, and managing
production-grade AI agents”. Provide a comprehensive list of criteria for what
“disciplined” and “engineering-driven” mean in this document.</p></blockquote><p>This pins the model to the source and shows if the doc has substance. After a
few rounds, you know if it’s worth a real read.</p><h2 id=limitations><a href=#limitations>#</a> Limitations</h2><p>This works as a filter. It breaks if you trust it blindly.</p><ul><li><strong>Hallucinations happen.</strong> I once asked about a new database’s WAL protocol.
The model said ARIES. Wrong – the paper invented a new one. It only
<em>compared</em> to ARIES. <strong>Always cross-check.</strong></li><li><strong>Nuance dies.</strong> Author’s pacing, careful build, caveats – gone. Don’t use
this for philosophy, law, or anything where structure <em>is</em> meaning.</li><li><strong>Complexity flattens.</strong> A summary makes a hard thing look simple. It’s
navigation aid, not expertise.</li></ul><h2 id=conclusion><a href=#conclusion>#</a> Conclusion</h2><p>This isn’t reading. It’s interrogation. Use it to slash through the pile of PDFs
and whitepapers. Then only read the ones that deserve your hours.</p></article></div></main><footer class=site-footer><a target=_blank rel="noopener noreferrer external" href=https://newsletter.bogomolov.work>Newsletter</a> | <a target=_blank href=/blog/index.xml>RSS</a></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-950H2PH48S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-950H2PH48S")</script><script>(function(e,t,n,s,o,i,a){e[o]=e[o]||function(){(e[o].a=e[o].a||[]).push(arguments)},e[o].l=1*new Date;for(var r=0;r<document.scripts.length;r++)if(document.scripts[r].src===s)return;i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym"),ym(100343675,"init",{clickmap:!0,trackLinks:!0,accurateTrackBounce:!0})</script><noscript><div><img src=https://mc.yandex.ru/watch/100343675 style=position:absolute;left:-9999px alt></div></noscript></body></html>